{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, pickle, cPickle, sys, urllib, gzip, sys\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['f', 'tanh']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "from IPython.display import Image as IPImage\n",
    "from PIL import Image\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from theano import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import get_output, InputLayer, DenseLayer, Upscale2DLayer, ReshapeLayer, MergeLayer\n",
    "from lasagne.nonlinearities import rectify, leaky_rectify, tanh,sigmoid\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from lasagne.objectives import categorical_crossentropy\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator, PrintLayerInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda_convnet (faster)\n"
     ]
    }
   ],
   "source": [
    "from lasagne.layers import Conv2DLayer as Conv2DLayerSlow\n",
    "from lasagne.layers import MaxPool2DLayer as MaxPool2DLayerSlow\n",
    "try:\n",
    "    from lasagne.layers.cuda_convnet import Conv2DCCLayer as Conv2DLayerFast\n",
    "    from lasagne.layers.cuda_convnet import MaxPool2DCCLayer as MaxPool2DLayerFast\n",
    "    print 'Using cuda_convnet (faster)'\n",
    "except ImportError, e:\n",
    "    print e\n",
    "    from lasagne.layers import Conv2DLayer as Conv2DLayerFast\n",
    "    from lasagne.layers import MaxPool2DLayer as MaxPool2DLayerFast\n",
    "    print 'Using lasagne.layers (slower)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = 'mnist/mnist.pkl.gz'\n",
    "if not os.path.isfile(fname):\n",
    "    testfile = urllib.URLopener()\n",
    "    testfile.retrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\", fname)\n",
    "f = gzip.open(fname, 'rb')\n",
    "train_set, valid_set, test_set = cPickle.load(f)\n",
    "f.close()\n",
    "X, y = train_set\n",
    "X = np.rint(X * 256).astype(np.int).reshape((-1, 1, 28,28)) # convert to (0,255) int range (we'll do our own scaling)\n",
    "mu, sigma = np.mean(X.flatten()), np.std(X.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eps = 1e-5\n",
    "\n",
    "X_train = X.astype(np.float64) / 255\n",
    "X_train = (1 - 2 * eps) * X_train + eps\n",
    "#X_train =(X_train - mu) / sigma\n",
    "X_train = X_train.astype(np.float32)\n",
    "\n",
    "# we need our target to be 1 dimensional\n",
    "X_out = X_train.reshape((X_train.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.9999997e-06, 0.99998999)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.min(), X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import Layer\n",
    "from lasagne.random import get_rng\n",
    "\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "class Q_Layer(MergeLayer):\n",
    "    \n",
    "    \n",
    "    def __init__(self, incomings, **kwargs):\n",
    "        super(Q_Layer, self).__init__(incomings, **kwargs)\n",
    "        self._srng = RandomStreams(get_rng().randint(1, 2147462579))\n",
    "        \n",
    "    def get_output_shape_for(self, input_shapes):\n",
    "        assert input_shapes[0] == input_shapes[1]\n",
    "        return input_shapes[0]\n",
    "\n",
    "    def get_output_for(self, inputs, deterministic=False, **kwargs):\n",
    "        mu, log_sigma = inputs\n",
    "        \n",
    "        out_shape = mu.shape\n",
    "        \n",
    "        return self._srng.normal(out_shape) * T.exp(log_sigma) + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_num_filters = 16\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "encode_size = 16\n",
    "dense_mid_size = 128\n",
    "pad_in = 'valid'\n",
    "pad_out = 'full'\n",
    "layers = [\n",
    "    (InputLayer, {'shape': (None, X.shape[1], X.shape[2], X.shape[3])}), \n",
    "    (Conv2DLayerFast, {'num_filters': conv_num_filters, 'filter_size': filter_size, 'pad': pad_in}),\n",
    "    (Conv2DLayerFast, {'num_filters': conv_num_filters, 'filter_size': filter_size, 'pad': pad_in}),\n",
    "    (MaxPool2DLayerFast, {'pool_size': pool_size}),\n",
    "    (Conv2DLayerFast, {'num_filters': 2*conv_num_filters, 'filter_size': filter_size, 'pad': pad_in}),\n",
    "    (MaxPool2DLayerFast, {'pool_size': pool_size}),\n",
    "    (ReshapeLayer, {'shape': (([0], -1))}),\n",
    "    (DenseLayer, {'num_units': dense_mid_size}),\n",
    "    (DenseLayer, {'name': 'encode', 'num_units': encode_size}),\n",
    "    (DenseLayer, {'num_units': dense_mid_size}),\n",
    "    (DenseLayer, {'num_units': 800}),\n",
    "    (ReshapeLayer, {'shape': (([0], 2*conv_num_filters, 5, 5))}),\n",
    "    (Upscale2DLayer, {'scale_factor': pool_size}),\n",
    "    (Conv2DLayerFast, {'num_filters': conv_num_filters, 'filter_size': filter_size, 'pad': pad_out}),\n",
    "    (Upscale2DLayer, {'scale_factor': pool_size}),\n",
    "    (Conv2DLayerSlow, {'num_filters': conv_num_filters, 'filter_size': filter_size, 'pad': pad_out}),\n",
    "    (Conv2DLayerSlow, {'num_filters': 1, 'filter_size': filter_size, 'pad': pad_out}),\n",
    "    (ReshapeLayer, {'shape': (([0], -1))}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_num_filters = 16\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "encode_size = 16\n",
    "dense_mid_size = 128\n",
    "pad_in = 'valid'\n",
    "pad_out = 'full'\n",
    "\n",
    "input_var = T.tensor4('inputs')\n",
    "target_var = T.matrix('targets')\n",
    "\n",
    "encode_hid = 256\n",
    "z_hid = 10\n",
    "decode_hid = 800\n",
    "\n",
    "input_layer = InputLayer(shape=(None, X.shape[1], X.shape[2], X.shape[3]), input_var=input_var)\n",
    "\n",
    "conv1 = Conv2DLayerFast(input_layer, num_filters= conv_num_filters, filter_size=filter_size, pad=pad_in)\n",
    "conv2 = Conv2DLayerFast(conv1, num_filters= conv_num_filters, filter_size=filter_size, pad=pad_in)\n",
    "pool1 = MaxPool2DLayerFast(conv2, pool_size=pool_size)\n",
    "conv3 = Conv2DLayerFast(pool1, num_filters= 2*conv_num_filters, filter_size=filter_size, pad=pad_in)\n",
    "pool2 = MaxPool2DLayerFast(conv3, pool_size= pool_size)\n",
    "\n",
    "reshape1 = ReshapeLayer(input_layer, shape=(([0], -1)))\n",
    "\n",
    "encode_h_layer = DenseLayer(reshape1, num_units=encode_hid, nonlinearity=None)\n",
    "mu_layer = DenseLayer(encode_h_layer, num_units=z_hid, nonlinearity=None)\n",
    "log_sigma_layer = DenseLayer(encode_h_layer, num_units=z_hid, nonlinearity=None)\n",
    "q_layer = Q_Layer([mu_layer, log_sigma_layer])\n",
    "decode_h_layer = DenseLayer(q_layer, num_units=decode_hid, nonlinearity=tanh)\n",
    "#network = DenseLayer(decode_h_layer, num_units= X.shape[2] * X.shape[3], nonlinearity=sigmoid)\n",
    "\n",
    "reshape2 = ReshapeLayer(decode_h_layer, shape= ([0], 2*conv_num_filters, 5, 5))\n",
    "\n",
    "upscale1 = Upscale2DLayer(reshape2, scale_factor=pool_size)\n",
    "deconv1 = Conv2DLayerFast(upscale1, num_filters=conv_num_filters, filter_size=filter_size, pad=pad_out)\n",
    "upscale2 = Upscale2DLayer(deconv1, scale_factor=pool_size)\n",
    "deconv2 = Conv2DLayerSlow(upscale2, num_filters=conv_num_filters, filter_size=filter_size, pad=pad_out)\n",
    "deconv3 = Conv2DLayerSlow(deconv2, num_filters=1, filter_size=filter_size, pad=pad_out, nonlinearity = sigmoid)\n",
    "\n",
    "network = ReshapeLayer(deconv3, shape=(([0], -1)))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = lasagne.layers.get_output(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kl_error(mu, log_sigma):  \n",
    "    return 0.5 * T.sum(1 + 2 * log_sigma - T.exp(2 * log_sigma) - T.sqr(mu), axis = 1)\n",
    "\n",
    "x_mu = get_output(mu_layer)\n",
    "x_logs = get_output(log_sigma_layer)\n",
    "\n",
    "kl_loss = kl_error(x_mu, x_logs).mean()\n",
    "\n",
    "rec_loss_raw = lasagne.objectives.binary_crossentropy(prediction, target_var)\n",
    "kl_loss_raw = kl_error(x_mu, x_logs)\n",
    "rec_loss = lasagne.objectives.binary_crossentropy(prediction, target_var).sum(axis = 1).mean()\n",
    "#rec_loss = lasagne.objectives.squared_error(prediction, target_var).sum(axis = 1).mean()\n",
    "\n",
    "loss = rec_loss - kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "#updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=0.001, momentum=0.9)\n",
    "updates = lasagne.updates.adam(loss, params)\n",
    "\n",
    "#test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "#test_loss = lasagne.objectives.squared_error(test_prediction, target_var)\n",
    "\n",
    "# Compile a function performing a training step on a mini-batch (by giving\n",
    "# the updates dictionary) and returning the corresponding training loss:\n",
    "train_fn = theano.function([input_var, target_var], [loss, rec_loss, kl_loss, \n",
    "                                                     kl_loss_raw, rec_loss_raw], updates=updates)\n",
    "\n",
    "# Compile a second function computing the validation loss and accuracy:\n",
    "#val_fn = theano.function([input_var, target_var], test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 0 of 100 took 5.025s\n",
      "  rec loss:\t\t150.342782\n",
      "  kl loss:\t\t19.173232\n",
      "  training loss:\t169.516014\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Finally, launch the training loop.\n",
    "print \"Starting training...\"\n",
    "# We iterate over epochs:\n",
    "for epoch in range(num_epochs):\n",
    "    sys.stdout.flush()\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    mse_err = 0\n",
    "    kl_err = 0\n",
    "    loss_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, X_out, 100, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        new_loss, new_mse, new_kl, kl_loss_raw, rec_loss_raw = train_fn(inputs, targets)\n",
    "        mse_err += new_mse\n",
    "        kl_err += new_kl\n",
    "        loss_err += new_loss\n",
    "        train_batches += 1\n",
    "    if epoch % 50 == 0 or epoch == num_epochs - 1:\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch, num_epochs, time.time() - start_time))\n",
    "        print(\"  rec loss:\\t\\t{:.6f}\".format(mse_err / train_batches))\n",
    "        print(\"  kl loss:\\t\\t{:.6f}\".format(- kl_err / train_batches))\n",
    "        print(\"  training loss:\\t{:.6f}\".format(loss_err / train_batches))\n",
    "        #print kl_loss_raw.shape\n",
    "        #print rec_loss_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = lasagne.layers.get_output(network)\n",
    "ae_encode = theano.function([input_var], output)\n",
    "X_train_pred = ae_encode(X_train[:1000]).reshape(-1, 28, 28) * 255\n",
    "X_pred = np.rint(X_train_pred).astype(int)\n",
    "X_pred = np.clip(X_pred, a_min = 0, a_max = 255)\n",
    "X_pred = X_pred.astype('uint8')\n",
    "print X_pred.shape , X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###  show random inputs / outputs side by side\n",
    "\n",
    "def get_picture_array(X, rescale=4):\n",
    "    array = X.reshape(28,28)\n",
    "    array = np.clip(array, a_min = 0, a_max = 255)\n",
    "    return  array.repeat(rescale, axis = 0).repeat(rescale, axis = 1).astype(np.uint8())\n",
    "\n",
    "def compare_images(index):\n",
    "    print index\n",
    "    original_image = Image.fromarray(get_picture_array(X[index]))\n",
    "    new_size = (original_image.size[0] * 2, original_image.size[1])\n",
    "    new_im = Image.new('L', new_size)\n",
    "    new_im.paste(original_image, (0,0))\n",
    "    rec_image = Image.fromarray(get_picture_array(X_pred[index]))\n",
    "    new_im.paste(rec_image, (original_image.size[0],0))\n",
    "    new_im.save('data/test.png', format=\"PNG\")\n",
    "    return IPImage('data/test.png')\n",
    "\n",
    "#compare_images(2)\n",
    "compare_images(np.random.randint(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-296-c411fa2429a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mencode_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_layer_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_layer_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encode'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_output_from_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ae' is not defined"
     ]
    }
   ],
   "source": [
    "## we find the encode layer from our ae, and use it to define an encoding function\n",
    "\n",
    "def get_layer_by_name(net, name):\n",
    "    for i, layer in enumerate(net.get_all_layers()):\n",
    "        if layer.name == name:\n",
    "            return layer, i\n",
    "    return None, None\n",
    "encode_layer, encode_layer_index = get_layer_by_name(ae, 'encode')\n",
    "\n",
    "def get_output_from_nn(last_layer, X, batch_size=128):\n",
    "    indices = np.arange(batch_size, X.shape[0], batch_size)\n",
    "    X_batches = np.split(X, indices)\n",
    "    out = []\n",
    "    for X_batch in X_batches:\n",
    "        out.append(get_output(last_layer, inputs=X_batch).eval())\n",
    "    return np.vstack(out)\n",
    "\n",
    "def encode_input(X):\n",
    "    return get_output_from_nn(encode_layer, X)\n",
    "\n",
    "X_encoded = encode_input(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next_layer = ae.get_all_layers()[encode_layer_index + 1]\n",
    "final_layer = ae.get_all_layers()[-1]\n",
    "new_layer = InputLayer(shape=(None, encode_layer.num_units))\n",
    "\n",
    "# N.B after we do this, we won't be able to use the original autoencoder , as the layers are broken up\n",
    "next_layer.input_layer = new_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAABoUlEQVR4nO3av0tWURzH8ZciLRK6\n6FLw0Cgtumm4uYQQRLugLY5u4eLiLtLS4NIfIA6Be9Cg4lIUbYGLOImBTgpSw3mgqevzi4dzvpwv\nXC6Xe859w/sD58e9d+SZ4dbokHkVWIEVWIEVWIEd1NigHziLbw334ystN8NlbGACO9j/T7v4SsvM\ncA6raOEa5w1t4ystM8N1zOARLnDc0Da+0vIyXMECxvEbHx9oH19pWRlO4g0et68/tY+miq+0rAw3\npTH0D06x3UGf+ErLyfAlXkhz4Dm2OuwXX2kZGY7jNZ62rw/wq8O+8ZWWkeFbaS8PX/G+i77xleaf\n4StpHTONG2k/303FV5p3hi1pLz+BW3zGUZfA+ErzznADz6V16Bne9QCMrzTfDGf8W4fe4hB3PQDj\nK803wzVpDoQTfOgRGF9pvhnOt8+XHn6f1lTxleaZ4QqeSGPod3zpAxhfaZ4ZLkrrmCvs9QmMrzS/\nDFvSfn5U+q502icwvtL8MlzCFO7xcwDA+Erzy/CH9E33GrsDAMZXOnTgSP1HuAIrsAIrsO/6C/9N\nMcCVK1gBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_encoded_input(X):\n",
    "    return get_output_from_nn(final_layer, X)\n",
    "\n",
    "X_decoded = decode_encoded_input(X_encoded[3]) * sigma + mu\n",
    "\n",
    "X_decoded = np.rint(X_decoded).astype(int)\n",
    "X_decoded = np.clip(X_decoded, a_min = 0, a_max = 255)\n",
    "X_decoded  = X_decoded.astype('uint8')\n",
    "print X_decoded.shape\n",
    "\n",
    "pic_array = get_picture_array(X_decoded, np.random.randint(len(X_decoded)))\n",
    "image = Image.fromarray(pic_array)\n",
    "image.save('data/test.png', format=\"PNG\")  \n",
    "IPImage('data/test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc_std = X_encoded.std(axis=0)\n",
    "enc_mean = X_encoded.mean(axis=0)\n",
    "enc_min = X_encoded.min(axis=0)\n",
    "enc_max = X_encoded.max(axis=0)\n",
    "m = X_encoded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 256\n",
    "generated = np.random.normal(0, 1, (n, m)) * enc_std + enc_mean\n",
    "generated = generated.astype(np.float32).clip(enc_min, enc_max)\n",
    "X_decoded = decode_encoded_input(generated) * sigma + mu\n",
    "X_decoded = np.rint(X_decoded ).astype(int)\n",
    "X_decoded = np.clip(X_decoded, a_min = 0, a_max = 255)\n",
    "X_decoded  = X_decoded.astype('uint8')\n",
    "!mkdir -p montage\n",
    "for i in range(n):\n",
    "    pic_array = get_picture_array(X_decoded, i, rescale=1)\n",
    "    image = Image.fromarray(pic_array)\n",
    "    image.save('montage/{0:03d}.png'.format(i), format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: montage: not found\r\n"
     ]
    },
    {
     "data": {
      "image/png": "bW9udGFnZS5wbmc=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!montage -mode concatenate -tile 16x montage/*.png montage.png\n",
    "IPImage('montage.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
